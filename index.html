<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jiayang Shi</title>

  <meta name="author" content="Jiayang Shi">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Jiayang Shi
                  </p>
                  <p>
                    I'm currently in my third year as a PhD student at <a href="https://liacs.leidenuniv.nl">Leiden
                      University</a>,
                    located in <a href="https://nl.wikipedia.org/wiki/Leiden">Leiden</a>, the Netherlands.
                    My supervisors are <a href="https://dmpelt.github.io">Daan Pelt</a> and <a
                      href="https://www.universiteitleiden.nl/medewerkers/joost-batenburg">Joost Batenburg</a>.
                  </p>
                  <p>
                    My research is part of the Marie Curie project, <a href="https://xcting-itn.eu">xCTing</a>.
                    I focus on integrating machine learning with denoising and artifact reduction techniques for <a
                      href="https://en.wikipedia.org/wiki/CT_scan">Computed Tomography (CT)</a> imaging.
                    This encompasses tomographic reconstruction and addressing <a
                      href="https://en.wikipedia.org/wiki/Inverse_problem">inverse problems</a> in general.
                  </p>
                  <p>
                    My PhD journey began in September 2021. Prior to this, I earned my bachelor's degree in 2013 from <a
                      href="https://en.wikipedia.org/wiki/Hangzhou">Hangzhou</a>, China,
                    and completed my master's in 2021 in <a
                      href="https://en.wikipedia.org/wiki/Karlsruhe">Karlsruhe</a>, Germany.
                  </p>

                  <p style="text-align:center">
                    <a href="mailto:j.shi@liacs.leidenuniv.nl">Email</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=9GJ3jyMAAAAJ&hl=en">Google Scholar</a>
                    &nbsp;/&nbsp;
                    <a href="https://github.com/jiayangshi">GitHub</a> &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/jiayangshi/">LinkedIn</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/JiayangShi.pdf"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/JiayangShi.pdf" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            
            <tbody>
              <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/inr4jointrecon.png' width="240">
              </td>
              <td style="padding:20px;width:65%;vertical-align:middle">
                <a href="https://github.com/jiayangshi/INR4JointCTRecon">
                  <span class="papertitle">Implicit Neural Representations for Robust Joint Sparse-View CT Reconstruction</span>
                </a>
                <br>
                <strong>Jiayang Shi</strong>,
                <a href="https://junyizhu-ai.github.io">Junyi Zhu</a>,
                <a href="https://dmpelt.github.io">Daan Pelt</a>,
                <a href="https://www.universiteitleiden.nl/medewerkers/joost-batenburg">Joost Batenburg</a>,
                <a href="https://homes.esat.kuleuven.be/~mblaschk/">Matthew Blaschko</a>
                <br>
                <em>Transactions on Machine Learning Research (TMLR) </em>, 2024 &nbsp
                <br>
                <a href="https://github.com/jiayangshi/INR4JointCTRecon">code</a>
                /
                <a href="https://openreview.net/forum?id=XCzuQI0oXR">openreview</a>
                /
                <a href="https://arxiv.org/abs/2405.02509">paper</a>
                <p>
                  A novel Bayesian framework for joint reconstruction of multiple objects from sparse-view CT scans using 
                  Implicit Neural Representations (INRs) to improve reconstruction quality. By capturing shared patterns across 
                  multiple objects with latent variables, our method enhances the reconstruction of each object, increases 
                  robustness to noise, and accelerates the learning process.
                </p>
              </td>
              </tr>
            </tbody>

            <tbody>
              <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/sr4zct.pdf' width="240">
              </td>
              <td style="padding:20px;width:65%;vertical-align:middle">
                <a href="https://github.com/jiayangshi/SR4ZCT">
                  <span class="papertitle">SR4ZCT: Self-supervised Through-plane Resolution Enhancement for CT Images with
                    Arbitrary Resolution and Overlap</span>
                </a>
                <br>
                <strong>Jiayang Shi</strong>,
                <a href="https://dmpelt.github.io">Daan Pelt</a>,
                <a href="https://www.universiteitleiden.nl/medewerkers/joost-batenburg">Joost Batenburg</a>,
                <br>
                <em>Machine Learning in Medical Imaging (MLMI) in conjunction with MICCAI </em>, 2023 &nbsp
                <br>
                <a href="https://github.com/jiayangshi/SR4ZCT">code</a>
                /
                <a href="https://link.springer.com/chapter/10.1007/978-3-031-45673-2_6">proceeding</a>
                /
                <a href="https://github.com/jiayangshi/SR4ZCT/blob/main/paper/Self_Supervised_Resolution_Enhancement_for_CT_Images.pdf">paper</a>
                <p>
                  A self-supervised approach utilizing off-axis training to improve the resolution of through-plane CT scans.
                  This method is trained using in-plane images and applied to through-plane images, offering flexibility with
                  any resolution and overlap.
                </p>
              </td>
              </tr>
            </tbody>        

            <tbody>
              <!-- color for stressing <tr onmouseout="multistage_stop()" onmouseover="multistage_start()" bgcolor="#ffffd0"></tr> -->
              <!-- <font color="red"><strong>(Oral Presentation)</strong></font> -->
              <!-- <tr onmouseout="multistage_stop()" onmouseover="multistage_start()"> -->
              <td style="padding:20px;width:35%;vertical-align:middle">
                <!-- <div class="one"> -->
                <!-- <div class="two" id='multistage_image'><video width=100% height=100% muted autoplay loop>
                        <source src="images/multistage.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div> -->
                <img src='images/multistage.pdf' width="240">
                <!-- </div> -->
                <!-- <script type="text/javascript">
                    function multistage_start() {
                      document.getElementById('multistage_image').style.opacity = "1";
                    }

                    function multistage_stop() {
                      document.getElementById('multistage_image').style.opacity = "0";
                    }
                    multistage_stop()
                  </script> -->
              </td>
              <td style="padding:20px;width:65%;vertical-align:middle">
                <a href="https://github.com/jiayangshi/Multi-stageArtifactReduction">
                  <span class="papertitle">Multi-stage Deep Learning Artifact Reduction for Computed Tomography</span>
                </a>
                <br>
                <strong>Jiayang Shi</strong>,
                <a href="https://dmpelt.github.io">Daan Pelt</a>,
                <a href="https://www.universiteitleiden.nl/medewerkers/joost-batenburg">Joost Batenburg</a>
                <br>
                <em>Under review</em>, 2023 &nbsp
                <br>
                <a href="https://github.com/jiayangshi/Multi-stageArtifactReduction">code</a>
                /
                <a href="https://arxiv.org/abs/2309.00494">arXiv</a>
                <p>
                  A artifact reduction method for CT images based on deep learning. Three CNNs reduce artifacts in a
                  subsequent manner,
                  targeting different types of artifacts. This method is seamlessly integrated into existing CT
                  pipelines.
                </p>
              </td>
      </tr>
    </tbody>

    <tbody>
      <td style="padding:20px;width:35%;vertical-align:middle">
        <img src='images/recon_n5.pdf' width="240">
      </td>
      <td style="padding:20px;width:65%;vertical-align:middle">
        <a href="https://github.com/jiayangshi/LoDoInd">
          <span class="papertitle">LoDoInd: Introducing A Benchmark Low-dose Industrial CT Dataset and Enhancing Denoising with 2.5D Deep Learning Techniques</span>
        </a>
        <br>
        <strong>Jiayang Shi</strong>,
        <a href="https://www.linkedin.com/in/omar-elkilany-046b0814b">Omar Elkilany</a>,
        <a href="https://www.linkedin.com/in/andreas-fischer-6a960b94">Andreas Fischer</a>,
        <a href="https://www.linkedin.com/in/alexander-suppes-554928a6">Alexander Suppes</a>,
        <a href="https://dmpelt.github.io">Daan Pelt</a>,
        <a href="https://www.universiteitleiden.nl/medewerkers/joost-batenburg">Joost Batenburg</a>
        <br>
        <em> International Conference on Industrial Computed Tomography (iCT) </em>, 2024 &nbsp
        <br>
        <a href="https://github.com/jiayangshi/LoDoInd">code</a>
        /
        <a href="https://zenodo.org/records/10356955">dataset</a>
        /
        <a href="https://www.ndt.net/article/ctc2024/papers/Contribution_187.pdf">proceeding</a>
        /
        <a href="https://github.com/jiayangshi/LoDoInd/blob/main/paper/LoDoInd_full.pdf">paper</a>
        <p>
          A Benchmark Low-dose Industrial CT Dataset Tailored for Deep Learning: This work introduces a dataset specifically designed for industrial CT applications, 
          emphasizing deep learning approaches. It features a comprehensive analysis comparing the effectiveness and efficiency of 2D, 2.5D, and 3D training methodologies 
          in the context of denoising and image enhancement.
        </p>
      </td>
      </tr>
    </tbody>

    <tbody>
      <td style="padding:20px;width:35%;vertical-align:middle">
        <img src='images/logs2graph.pdf' width="240">
      </td>
      <td style="padding:20px;width:65%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2307.00527">
          <span class="papertitle">Graph Neural Network based Log Anomaly Detection and Explanation</span>
        </a>
        <br>
        <a href="https://www.zhongli.nl">Zhong Li</a>,
        <strong>Jiayang Shi</strong>,
        <a href="https://patternsthatmatter.org">Matthijs van Leeuwen</a>
        <br>
        <em>Under review </em>, 2023 &nbsp
        <br>
        <a href="https://github.com/ZhongLIFR/Logs2Graph">code</a>
        /
        <a href="https://arxiv.org/abs/2307.00527">arXiv</a>
        <p>
          Graph neural network for log anomaly detection.
        </p>
      </td>
      </tr>
    </tbody>

    <tbody>
      <td style="padding:20px;width:35%;vertical-align:middle">
        <img src='images/spectrallightfield.png' width="240">
      </td>
      <td style="padding:20px;width:65%;vertical-align:middle">
        <a href="https://gitlab.com/MaxSchambach/reconstruction-from-spectrally-coded-light-fields">
          <span class="papertitle">Spectral reconstruction and disparity from spatio-spectrally coded light fields via
            multi-task deep learning</span>
        </a>
        <br>
        <a href="https://maxschambach.github.io">Maximilian Schambach</a>,
        <strong>Jiayang Shi</strong>,
        <a href="https://www.iiit.kit.edu/english/3252.php">Michael Heizmann</a>
        <br>
        <em>3DV </em>, 2021 &nbsp
        <br>
        <a href="https://gitlab.com/MaxSchambach/reconstruction-from-spectrally-coded-light-fields">code</a>
        /
        <a href="https://ieeexplore.ieee.org/abstract/document/9665944">proceeding</a>
        /
        <a href="https://arxiv.org/abs/2103.10179">arXiv</a>
        <p></p>
        <p>
          A novel method to reconstruct a spectral central view and its aligned disparity map from spatio-spectrally
          coded light fields using multi-task deep learning.
        </p>
      </td>
      </tr>
    </tbody>

  </table>


  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td>
          <h2>Teaching Assistant</h2>
        </td>
      </tr>
    </tbody>
  </table>
  <table width="100%" align="center" border="0" cellpadding="20">
    <tbody>
      <tr>
        <td width="100%" valign="center">
          Computational Imaging and Tomography <a href="https://studiegids.universiteitleiden.nl/en/courses/105162/computational-imaging-and-tomography">2022 spring</a>&<a href="https://studiegids.universiteitleiden.nl/en/courses/118883/computational-imaging-and-tomography">2024 spring</a>
          <br>
          <a href="https://studiegids.universiteitleiden.nl/courses/116593/statistics-for-computer-scientists">Statistics
            for Computer Scientists, 2023 fall</a>
          <br>
          <a href="https://studiegids.universiteitleiden.nl/courses/129010/computer-vision">Computer Vision, 2024 fall</a>
        </td>
      </tr>
    </tbody>
  </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td>
          <h2>Supervised Thesis</h2>
        </td>
      </tr>
    </tbody>
  </table>
  <table width="100%" align="center" border="0" cellpadding="20">
    <tbody>
      <tr>
        <td width="100%" valign="center">
          <p>
            <a href="https://www.linkedin.com/in/donghang-lyu-a795a4197/">Donghang Lyu</a> (master student): <a
              href="https://theses.liacs.nl/2546">Res-Swin: Effective Combination of ResNet and Swin Transformer for
              LDCT Denoising</a>
            <br>
            <a href="https://www.linkedin.com/in/donghang-lyu-a795a4197/">Omar Elkilany</a> (master student@TUM & WayGate): <a
            href="https://www.linkedin.com/in/omar-elkilany-046b0814b/">Beam Hardening Correction using Implicit Neural Representations</a>
          </p>
        </td>
      </tr>
    </tbody>
  </table>

  </td>
  </tr>
  </table>
</body>

</html>